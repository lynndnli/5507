{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "65f35184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 tokenz  sexism_score  \\\n",
      "0                                很见 皮肤 女玩家 皮肤 男玩家 刷女 皮肤      0.000000   \n",
      "1     王者 辱女 玩家 事情 单排 排位 我楼 常用英雄 法师 常用 法师 进去 预选 玩法 上来...      0.053333   \n",
      "2                                           弈星 玩家 弈星 撕漫      0.000000   \n",
      "3           低分 男玩家 喜欢 破防 造谣 一言不合 有本事 自行 避雷 西施 王者 低素质 玩家      0.000000   \n",
      "4                          叫我 女玩家 角色 皮肤 男玩家 刷女 角色 皮肤 皮肤      0.000000   \n",
      "...                                                 ...           ...   \n",
      "2724                     女孩子 厉害 视频 无关 讲话 妹子 不停 露娜 不断 得意      0.000000   \n",
      "2725                                                NaN      0.000000   \n",
      "2726                                神秘 女玩家 完结 接下来 自行 想象      0.000000   \n",
      "2727  女生 脑残 小编 暑假 在家 一门 不出 二门 不迈 王者 追剧 害羞 出了名 小区 宅女 ...      0.000000   \n",
      "2728                               一枚 女玩家 日常 凑数 捂脸捂脸 捂脸      0.000000   \n",
      "\n",
      "      aggressive_score  incivility_score  competitive_score  \\\n",
      "0                  0.0          0.000000                0.0   \n",
      "1                  0.0          0.040000                0.0   \n",
      "2                  0.0          0.000000                0.0   \n",
      "3                  0.0          0.076923                0.0   \n",
      "4                  0.0          0.000000                0.0   \n",
      "...                ...               ...                ...   \n",
      "2724               0.0          0.000000                0.1   \n",
      "2725               0.0          0.000000                0.0   \n",
      "2726               0.0          0.000000                0.0   \n",
      "2727               0.0          0.000000                0.0   \n",
      "2728               0.0          0.000000                0.0   \n",
      "\n",
      "      incompetitive_score  \n",
      "0                0.000000  \n",
      "1                0.026667  \n",
      "2                0.000000  \n",
      "3                0.000000  \n",
      "4                0.000000  \n",
      "...                   ...  \n",
      "2724             0.000000  \n",
      "2725             0.000000  \n",
      "2726             0.000000  \n",
      "2727             0.000000  \n",
      "2728             0.000000  \n",
      "\n",
      "[2729 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV file\n",
    "file_path = '/Users/Lynn/Downloads/red/PP_merged1.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Your word lists\n",
    "sexism_word_list = ['厌女', '歧视', '性别歧视', '带妹', '渣男', '辱女', '普信男', '下头男']\n",
    "incivility_word_list = ['辱骂', '骂', '骂人', 'fw', '喷子', '骂脏话', '羞辱', '讽刺', '恶臭', '看不起', '卧龙凤雏', '恶心', '矫情', '垃圾', '开骂', '嘲讽', '侮辱','低素质', '狗屁','喷粪','傻子']\n",
    "aggressive_word_list = ['欺负','怼','强势','抢位置','抢线']\n",
    "competitive_word_list = ['带飞', '野王', '顺风', 'c位', '上分', '至尊', '反野','赢','实力','连胜','厉害']\n",
    "incompetitive_word_list = ['菜', '躺', '逆风', '挂机','划水','演员','软饭','摆烂','打不过']\n",
    "submissive_word_list = ['辅助','软辅','带妹','求求','妹妹','大乔','蔡文姬','瑶','女英雄']\n",
    "\n",
    "# Function to calculate score based on a word list\n",
    "def calculate_score(tokenz, word_list):\n",
    "    if isinstance(tokenz, float) or (not isinstance(tokenz, (list, str))):\n",
    "        return 0\n",
    "    tokens = tokenz.split() if isinstance(tokenz, str) else tokenz\n",
    "    count = sum(token in word_list for token in tokens)\n",
    "    score = count / len(tokens) if len(tokens) > 0 else 0\n",
    "    return score\n",
    "\n",
    "# Apply the function to calculate the scores for each row\n",
    "data['sexism_score'] = data['tokenz'].apply(lambda x: calculate_score(x, sexism_word_list))\n",
    "data['aggressive_score'] = data['tokenz'].apply(lambda x: calculate_score(x, aggressive_word_list))\n",
    "data['incivility_score'] = data['tokenz'].apply(lambda x: calculate_score(x, incivility_word_list))\n",
    "data['competitive_score'] = data['tokenz'].apply(lambda x: calculate_score(x, competitive_word_list))\n",
    "data['incompetitive_score'] = data['tokenz'].apply(lambda x: calculate_score(x, incompetitive_word_list))\n",
    "data['submissive_score'] = data['tokenz'].apply(lambda x: calculate_score(x, submissive_word_list))\n",
    "\n",
    "# Save the updated DataFrame back to a CSV file or use it for further analysis\n",
    "data.to_csv('/Users/Lynn/Downloads/red/PP_merged_with_scores.csv', index=False)\n",
    "\n",
    "# View the resulting DataFrame\n",
    "print(data[['tokenz', 'sexism_score', 'aggressive_score', 'incivility_score', 'competitive_score', 'incompetitive_score']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b706581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "incivility count (hurdle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a509c83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 tokenz  sexism_score  \\\n",
      "0                                很见 皮肤 女玩家 皮肤 男玩家 刷女 皮肤      0.000000   \n",
      "1     王者 辱女 玩家 事情 单排 排位 我楼 常用英雄 法师 常用 法师 进去 预选 玩法 上来...      0.053333   \n",
      "2                                           弈星 玩家 弈星 撕漫      0.000000   \n",
      "3           低分 男玩家 喜欢 破防 造谣 一言不合 有本事 自行 避雷 西施 王者 低素质 玩家      0.000000   \n",
      "4                          叫我 女玩家 角色 皮肤 男玩家 刷女 角色 皮肤 皮肤      0.000000   \n",
      "...                                                 ...           ...   \n",
      "2724                     女孩子 厉害 视频 无关 讲话 妹子 不停 露娜 不断 得意      0.000000   \n",
      "2725                                                NaN      0.000000   \n",
      "2726                                神秘 女玩家 完结 接下来 自行 想象      0.000000   \n",
      "2727  女生 脑残 小编 暑假 在家 一门 不出 二门 不迈 王者 追剧 害羞 出了名 小区 宅女 ...      0.000000   \n",
      "2728                               一枚 女玩家 日常 凑数 捂脸捂脸 捂脸      0.000000   \n",
      "\n",
      "      aggressive_score  incivility_count  competitive_score  \\\n",
      "0                  0.0                 0                0.0   \n",
      "1                  0.0                 3                0.0   \n",
      "2                  0.0                 0                0.0   \n",
      "3                  0.0                 1                0.0   \n",
      "4                  0.0                 0                0.0   \n",
      "...                ...               ...                ...   \n",
      "2724               0.0                 0                0.1   \n",
      "2725               0.0                 0                0.0   \n",
      "2726               0.0                 0                0.0   \n",
      "2727               0.0                 0                0.0   \n",
      "2728               0.0                 0                0.0   \n",
      "\n",
      "      incompetitive_score  submissive_score  \n",
      "0                0.000000               0.0  \n",
      "1                0.026667               0.0  \n",
      "2                0.000000               0.0  \n",
      "3                0.000000               0.0  \n",
      "4                0.000000               0.0  \n",
      "...                   ...               ...  \n",
      "2724             0.000000               0.0  \n",
      "2725             0.000000               0.0  \n",
      "2726             0.000000               0.0  \n",
      "2727             0.000000               0.0  \n",
      "2728             0.000000               0.0  \n",
      "\n",
      "[2729 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV file\n",
    "file_path = '/Users/Lynn/Downloads/red/PP_merged1.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Your word lists\n",
    "sexism_word_list = ['厌女', '歧视', '性别歧视', '带妹', '渣男', '辱女', '普信男', '下头男','网络公主']\n",
    "incivility_word_list = ['辱骂', '骂', '骂人','骂我', 'fw', '喷子', '骂脏话', '羞辱', '讽刺', '恶臭', '看不起', 'sb', '生殖器', '恶心', '矫情', '垃圾', '开骂', '嘲讽', '侮辱','低素质', '狗屁','喷粪','傻子','造黄谣','弱智']\n",
    "aggressive_word_list = ['欺负','怼','强势','抢位置','抢线','抢','抢中','抢人头']\n",
    "competitive_word_list = ['带飞', '野王', '顺风', 'mvp', 'c位', '上分', '至尊', '反野','赢','实力','连胜','厉害']\n",
    "incompetitive_word_list = ['菜', '躺', '逆风', '挂机','划水','演员','软饭','摆烂','打不过','坑','混子']\n",
    "submissive_word_list = ['辅助','软辅','带妹','求求','妹妹','大乔','蔡文姬','瑶','瑶妹','孙膑']\n",
    "\n",
    "# Function to calculate score based on a word list\n",
    "def calculate_score(tokenz, word_list):\n",
    "    if isinstance(tokenz, float) or (not isinstance(tokenz, (list, str))):\n",
    "        return 0\n",
    "    tokens = tokenz.split() if isinstance(tokenz, str) else tokenz\n",
    "    count = sum(token in word_list for token in tokens)\n",
    "    score = count / len(tokens) if len(tokens) > 0 else 0\n",
    "    return score\n",
    "\n",
    "# Function to calculate count of specific words in a token list\n",
    "def calculate_count(tokenz, word_list):\n",
    "    if isinstance(tokenz, float) or (not isinstance(tokenz, (list, str))):\n",
    "        return 0\n",
    "    tokens = tokenz.split() if isinstance(tokenz, str) else tokenz\n",
    "    count = sum(token in word_list for token in tokens)\n",
    "    return count\n",
    "\n",
    "# Apply the functions to calculate the scores and count for each row\n",
    "data['sexism_score'] = data['tokenz'].apply(lambda x: calculate_score(x, sexism_word_list))\n",
    "data['aggressive_score'] = data['tokenz'].apply(lambda x: calculate_score(x, aggressive_word_list))\n",
    "data['incivility_count'] = data['tokenz'].apply(lambda x: calculate_count(x, incivility_word_list)) # Updated\n",
    "data['competitive_score'] = data['tokenz'].apply(lambda x: calculate_score(x, competitive_word_list))\n",
    "data['incompetitive_score'] = data['tokenz'].apply(lambda x: calculate_score(x, incompetitive_word_list))\n",
    "data['submissive_score'] = data['tokenz'].apply(lambda x: calculate_score(x, submissive_word_list))\n",
    "\n",
    "# Save the updated DataFrame back to a CSV file or use it for further analysis\n",
    "data.to_csv('/Users/Lynn/Downloads/red/PP_merged_with_scores.csv', index=False)\n",
    "\n",
    "# View the resulting DataFrame\n",
    "print(data[['tokenz', 'sexism_score', 'aggressive_score', 'incivility_count', 'competitive_score', 'incompetitive_score', 'submissive_score']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee8d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "all variable count (hurdle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "30055ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 tokenz  sexism_count  \\\n",
      "0                      王者荣耀 很见 王者荣耀 皮肤 女玩家 皮肤 男玩家 刷女 皮肤             0   \n",
      "1     王者 碰到 辱女 玩家 事情 单排 排位 我楼 常用英雄 全是 法师 常用 法师 进去 之后...             4   \n",
      "2                                      弈星 玩家 弈星 王者荣耀 撕漫             0   \n",
      "3     低分 男玩家 喜欢 破防 造谣 一言不合 有本事 自行 避雷 王者荣耀 西施 王者 王者荣耀...             0   \n",
      "4             叫我 小王 女玩家 角色 皮肤 男玩家 刷女 角色 皮肤 王者荣耀 王者荣耀 皮肤             0   \n",
      "...                                                 ...           ...   \n",
      "2257                                                NaN             0   \n",
      "2258                     非常 真实 单篇 中单 英雄 真多 汗颜 王者荣耀 王者荣耀             0   \n",
      "2259  来个 中辅 带你 赢了 记得 大声 露娜 带飞 走路 就行 体验 连胜 快乐 王者上分 日常...             0   \n",
      "2260  女生 只会 小乔 安琪拉 来做 女野王 打野 哥哥 不会 貂蝉 帅哥 貂蝉 王者荣耀 国服 ...             0   \n",
      "2261  原来 王者 峡谷 有人 歧视女玩家 被骂 整局 开麦 以后 发现 女生 更厉害 不会玩 不会...             0   \n",
      "\n",
      "      aggressive_count  incivility_count  competitive_count  \\\n",
      "0                    0                 0                  0   \n",
      "1                    0                 3                  0   \n",
      "2                    0                 0                  0   \n",
      "3                    0                 1                  0   \n",
      "4                    0                 0                  0   \n",
      "...                ...               ...                ...   \n",
      "2257                 0                 0                  0   \n",
      "2258                 0                 0                  0   \n",
      "2259                 0                 0                  2   \n",
      "2260                 0                 0                  0   \n",
      "2261                 0                 0                  0   \n",
      "\n",
      "      incompetitive_count  submissive_count  \n",
      "0                       0                 0  \n",
      "1                       2                 0  \n",
      "2                       0                 0  \n",
      "3                       0                 0  \n",
      "4                       0                 0  \n",
      "...                   ...               ...  \n",
      "2257                    0                 0  \n",
      "2258                    0                 0  \n",
      "2259                    0                 0  \n",
      "2260                    0                 0  \n",
      "2261                    0                 0  \n",
      "\n",
      "[2262 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV file\n",
    "file_path = '/Users/Lynn/Downloads/codes/merged_data_unique.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Your word lists\n",
    "sexism_word_list = ['厌女', '歧视', '性别歧视', '带妹', '渣男', '辱女', '普信男', '下头男','网络公主']\n",
    "incivility_word_list = ['辱骂', '骂', '骂人','骂我', 'fw', '喷子', '骂脏话', '羞辱', '讽刺', '恶臭', '看不起', 'sb', '生殖器', '恶心', '矫情', '垃圾', '开骂', '嘲讽', '侮辱','低素质', '狗屁','喷粪','傻子','造黄谣','弱智']\n",
    "aggressive_word_list = ['欺负','怼','强势','抢位置','抢线','抢','抢中','抢人头','抢经济']\n",
    "competitive_word_list = ['带飞', '野王', '顺风', 'mvp', 'c位', '上分', '至尊', '反野','赢','实力','连胜','厉害']\n",
    "incompetitive_word_list = ['菜', '躺', '逆风', '挂机','划水','演员','软饭','摆烂','打不过','坑','混子']\n",
    "submissive_word_list = ['辅助','软辅','带妹','求求','妹妹','大乔','蔡文姬','瑶','瑶妹','孙膑']\n",
    "\n",
    "# Function to calculate score based on a word list\n",
    "def calculate_score(tokenz, word_list):\n",
    "    if isinstance(tokenz, float) or (not isinstance(tokenz, (list, str))):\n",
    "        return 0\n",
    "    tokens = tokenz.split() if isinstance(tokenz, str) else tokenz\n",
    "    count = sum(token in word_list for token in tokens)\n",
    "    score = count / len(tokens) if len(tokens) > 0 else 0\n",
    "    return score\n",
    "\n",
    "# Function to calculate count of specific words in a token list\n",
    "def calculate_count(tokenz, word_list):\n",
    "    if isinstance(tokenz, float) or (not isinstance(tokenz, (list, str))):\n",
    "        return 0\n",
    "    tokens = tokenz.split() if isinstance(tokenz, str) else tokenz\n",
    "    count = sum(token in word_list for token in tokens)\n",
    "    return count\n",
    "\n",
    "# Apply the functions to calculate the scores and count for each row\n",
    "data['sexism_count'] = data['tokenz'].apply(lambda x: calculate_count(x, sexism_word_list))\n",
    "data['aggressive_count'] = data['tokenz'].apply(lambda x: calculate_count(x, aggressive_word_list))\n",
    "data['incivility_count'] = data['tokenz'].apply(lambda x: calculate_count(x, incivility_word_list)) # Updated\n",
    "data['competitive_count'] = data['tokenz'].apply(lambda x: calculate_count(x, competitive_word_list))\n",
    "data['incompetitive_count'] = data['tokenz'].apply(lambda x: calculate_count(x, incompetitive_word_list))\n",
    "data['submissive_count'] = data['tokenz'].apply(lambda x: calculate_count(x, submissive_word_list))\n",
    "\n",
    "# Save the updated DataFrame back to a CSV file or use it for further analysis\n",
    "data.to_csv('/Users/Lynn/Downloads/codes/PP_mergedtheta_1214.csv', index=False)\n",
    "\n",
    "# View the resulting DataFrame\n",
    "print(data[['tokenz', 'sexism_count', 'aggressive_count', 'incivility_count', 'competitive_count', 'incompetitive_count', 'submissive_count']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "afc46f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       incivility_score   R-squared:                       0.031\n",
      "Model:                            OLS   Adj. R-squared:                  0.029\n",
      "Method:                 Least Squares   F-statistic:                     11.15\n",
      "Date:                Wed, 13 Dec 2023   Prob (F-statistic):           6.02e-14\n",
      "Time:                        17:03:41   Log-Likelihood:                 5871.1\n",
      "No. Observations:                2413   AIC:                        -1.173e+04\n",
      "Df Residuals:                    2405   BIC:                        -1.168e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  -0.0108      0.003     -3.263      0.001      -0.017      -0.004\n",
      "aggressive_score        0.0072      0.065      0.110      0.912      -0.121       0.135\n",
      "competitive_score      -0.0166      0.007     -2.280      0.023      -0.031      -0.002\n",
      "incompetitive_score     0.0335      0.037      0.896      0.371      -0.040       0.107\n",
      "female                 -0.0028      0.001     -3.235      0.001      -0.005      -0.001\n",
      "sexism_score            0.1073      0.018      5.867      0.000       0.071       0.143\n",
      "months_since_min        0.0003   6.01e-05      4.905      0.000       0.000       0.000\n",
      "post_length          2.468e-05   1.01e-05      2.442      0.015    4.86e-06    4.45e-05\n",
      "==============================================================================\n",
      "Omnibus:                     3168.360   Durbin-Watson:                   2.025\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           541402.962\n",
      "Skew:                           7.322   Prob(JB):                         0.00\n",
      "Kurtosis:                      74.905   Cond. No.                     9.86e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 9.86e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "\n",
    "# Load your data\n",
    "file_path = '/Users/Lynn/Downloads/red/PP_merged_with_scores.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data['female'] = data['Label'].apply(lambda x: 1 if x == 'F' else 0)\n",
    "\n",
    "\n",
    "# Convert 'publish_time' to datetime format\n",
    "data['publish_time'] = pd.to_datetime(data['publish_time'])\n",
    "\n",
    "# Calculate the minimum publish time\n",
    "min_date = data['publish_time'].min()\n",
    "\n",
    "# Calculate the difference in months\n",
    "# (year difference * 12) + month difference\n",
    "data['months_since_min'] = ((data['publish_time'].dt.year - min_date.year) * 12) + (data['publish_time'].dt.month - min_date.month)\n",
    "\n",
    "# Count the number of words in each post\n",
    "data = data[data['tokenz'].notna()]\n",
    "data['post_length'] = data['tokenz'].str.split().str.len()\n",
    "\n",
    "# Define your independent variables (IVs) and dependent variable (DV)\n",
    "X = data[['aggressive_score','competitive_score','incompetitive_score','female',\"sexism_score\",'months_since_min','post_length']]\n",
    "y = data['incivility_score']                    # DV\n",
    "\n",
    "# Normalize the independent variables\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert the normalized array back to a DataFrame\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Add a constant to the model (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print out the statistics\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411aa215",
   "metadata": {},
   "outputs": [],
   "source": [
    "hurdle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e4df2bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.248049\n",
      "         Iterations 8\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Hurdle Model - Stage 1: Binary Model (Logistic Regression)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Create a binary outcome for whether incivility_score is positive\u001b[39;00m\n\u001b[1;32m     43\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive_incivility\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincivility_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m model_logit \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mLogit(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive_incivility\u001b[39m\u001b[38;5;124m'\u001b[39m], X_scaled)\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Hurdle Model - Stage 2: Zero-Truncated Count Model (Poisson or Negative Binomial)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Filter data to include only positive counts\u001b[39;00m\n\u001b[1;32m     48\u001b[0m data_positive \u001b[38;5;241m=\u001b[39m data[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincivility_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:2599\u001b[0m, in \u001b[0;36mLogit.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m   2596\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(DiscreteModel\u001b[38;5;241m.\u001b[39mfit\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m)\n\u001b[1;32m   2597\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, start_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton\u001b[39m\u001b[38;5;124m'\u001b[39m, maxiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m35\u001b[39m,\n\u001b[1;32m   2598\u001b[0m         full_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, disp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2599\u001b[0m     bnryfit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(start_params\u001b[38;5;241m=\u001b[39mstart_params,\n\u001b[1;32m   2600\u001b[0m                           method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m   2601\u001b[0m                           maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[1;32m   2602\u001b[0m                           full_output\u001b[38;5;241m=\u001b[39mfull_output,\n\u001b[1;32m   2603\u001b[0m                           disp\u001b[38;5;241m=\u001b[39mdisp,\n\u001b[1;32m   2604\u001b[0m                           callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m   2605\u001b[0m                           \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2607\u001b[0m     discretefit \u001b[38;5;241m=\u001b[39m LogitResults(\u001b[38;5;28mself\u001b[39m, bnryfit)\n\u001b[1;32m   2608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BinaryResultsWrapper(discretefit)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:243\u001b[0m, in \u001b[0;36mDiscreteModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# TODO: make a function factory to have multiple call-backs\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m mlefit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(start_params\u001b[38;5;241m=\u001b[39mstart_params,\n\u001b[1;32m    244\u001b[0m                      method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    245\u001b[0m                      maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[1;32m    246\u001b[0m                      full_output\u001b[38;5;241m=\u001b[39mfull_output,\n\u001b[1;32m    247\u001b[0m                      disp\u001b[38;5;241m=\u001b[39mdisp,\n\u001b[1;32m    248\u001b[0m                      callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    249\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mlefit\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:582\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m     Hinv \u001b[38;5;241m=\u001b[39m cov_params_func(\u001b[38;5;28mself\u001b[39m, xopt, retvals)\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m full_output:\n\u001b[0;32m--> 582\u001b[0m     Hinv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(\u001b[38;5;241m-\u001b[39mretvals[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHessian\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m/\u001b[39m nobs\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_hessian:\n\u001b[1;32m    584\u001b[0m     H \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhessian(xopt)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/linalg/linalg.py:538\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    536\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    537\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m--> 538\u001b[0m ainv \u001b[38;5;241m=\u001b[39m _umath_linalg\u001b[38;5;241m.\u001b[39minv(a, signature\u001b[38;5;241m=\u001b[39msignature, extobj\u001b[38;5;241m=\u001b[39mextobj)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/linalg/linalg.py:89\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "\n",
    "# Load your data\n",
    "file_path = '/Users/Lynn/Downloads/red/PP_merged_with_scores.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocessing steps...\n",
    "data['female'] = data['Label'].apply(lambda x: 1 if x == 'F' else 0)\n",
    "\n",
    "\n",
    "# Convert 'publish_time' to datetime format\n",
    "data['publish_time'] = pd.to_datetime(data['publish_time'])\n",
    "\n",
    "# Calculate the minimum publish time\n",
    "min_date = data['publish_time'].min()\n",
    "\n",
    "# Calculate the difference in months\n",
    "# (year difference * 12) + month difference\n",
    "data['months_since_min'] = ((data['publish_time'].dt.year - min_date.year) * 12) + (data['publish_time'].dt.month - min_date.month)\n",
    "\n",
    "# Count the number of words in each post\n",
    "data = data[data['tokenz'].notna()]\n",
    "data['post_length'] = data['tokenz'].str.split().str.len()\n",
    "\n",
    "\n",
    "# Normalize the independent variables\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "X_scaled = sm.add_constant(X_scaled)\n",
    "\n",
    "# Reset the index of your data to align indices\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "X_scaled.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Hurdle Model - Stage 1: Binary Model (Logistic Regression)\n",
    "# Create a binary outcome for whether incivility_score is positive\n",
    "data['positive_incivility'] = (data['incivility_score'] > 0).astype(int)\n",
    "model_logit = sm.Logit(data['positive_incivility'], X_scaled).fit()\n",
    "\n",
    "# Hurdle Model - Stage 2: Zero-Truncated Count Model (Poisson or Negative Binomial)\n",
    "# Filter data to include only positive counts\n",
    "data_positive = data[data['incivility_score'] > 0]\n",
    "X_scaled_positive = X_scaled[data['incivility_score'] > 0]\n",
    "\n",
    "# Assuming Poisson regression for the count part; you can also consider Negative Binomial\n",
    "model_count = sm.GLM(data_positive['incivility_score'], X_scaled_positive, family=sm.families.Poisson()).fit()\n",
    "\n",
    "# Print summaries of both parts of the hurdle model\n",
    "print(\"Logistic Regression Part (Binary):\")\n",
    "print(model_logit.summary())\n",
    "print(\"\\nCount Model Part (Poisson Regression):\")\n",
    "print(model_count.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc911ee4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnote_id\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m column is missing in one of the DataFrames.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Check and handle missing/infinite values\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m merged_data\u001b[38;5;241m.\u001b[39mreplace([np\u001b[38;5;241m.\u001b[39minf, \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf], np\u001b[38;5;241m.\u001b[39mnan, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Replace inf with NaN\u001b[39;00m\n\u001b[1;32m     21\u001b[0m merged_data\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Remove rows with NaN values\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Define your independent variables (IVs) including topic proportions\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Include the columns from theta_df that represent the topic proportions\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Replace 'topic1', 'topic2', etc., with your actual topic column names\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load your main data\n",
    "file_path = '/Users/Lynn/Downloads/red/PP_merged_with_scores.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Create a binary 'female' column based on the 'Label' column\n",
    "data['female'] = data['Label'].apply(lambda x: 1 if x == 'F' else 0)\n",
    "\n",
    "# Load the theta matrix\n",
    "theta_path = '/Users/Lynn/Downloads/codes/theta_with_ids.csv'  # Replace with the actual path to your theta matrix file\n",
    "theta_df = pd.read_csv(theta_path)\n",
    "\n",
    "# Ensure that both DataFrames have a 'note_id' column for merging\n",
    "if 'note_id' not in data.columns or 'note_id' not in theta_df.columns:\n",
    "    raise ValueError(\"The 'note_id' column is missing in one of the DataFrames.\")\n",
    "\n",
    "# Check and handle missing/infinite values\n",
    "merged_data.replace([np.inf, -np.inf], np.nan, inplace=True)  # Replace inf with NaN\n",
    "merged_data.dropna(inplace=True)  # Remove rows with NaN values\n",
    "\n",
    "# Define your independent variables (IVs) including topic proportions\n",
    "# Include the columns from theta_df that represent the topic proportions\n",
    "# Replace 'topic1', 'topic2', etc., with your actual topic column names\n",
    "X = merged_data[['aggressive_score', 'competitive_score', 'incompetitive_score', 'female','X3']]\n",
    "\n",
    "# Define your dependent variable (DV)\n",
    "y = merged_data['sexism_score']\n",
    "\n",
    "# Add a constant to the model (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print out the statistics\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a41140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db46d19b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
